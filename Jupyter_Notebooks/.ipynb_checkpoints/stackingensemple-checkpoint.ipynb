{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential, Model\n",
    "num_classes=6\n",
    "def fit_model(trainX, trainy):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(1, img_rows), strides=(1, 1),input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(1, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.45), bias_regularizer=l2(0.40)))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='Adam',\n",
    "                      metrics=['accuracy'])\n",
    "    model.fit(trainX, trainy,\n",
    "                      batch_size=100,\n",
    "                      epochs=100)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## 173 Genes Women Cancer##########################################\n",
    "Dataset=pd.read_csv('../input/genepreprocessedwithlasso/Data174genes.csv')\n",
    "\n",
    "Dataset = Dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "Dataset.drop(Dataset.columns[0], inplace=True, axis=1)\n",
    "Y=Dataset.pop(Dataset.columns[-1])\n",
    "XO=Dataset\n",
    "XO.shape[1]\n",
    "M=XO.shape[0]\n",
    "N=XO.shape[1]\n",
    "X = np.zeros((M,N+9))\n",
    "X[:,:-9] = XO\n",
    "X = np.reshape(X, (-1, 13, 14))\n",
    "img_rows, img_cols = len(X[0]), len(X[0][0])\n",
    "img_rows\n",
    "num_classes=5\n",
    "X=X/255\n",
    "\n",
    "#Y = to_categorical(Y)\n",
    "\n",
    "X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "n_train = 1624\n",
    "\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = Y[:n_train], Y[n_train:]\n",
    "\n",
    "print(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "#makedirs('models')\n",
    "print (trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_members = 5\n",
    "for i in range(n_members):\n",
    "    #fit model\n",
    "    model = fit_model(trainX, trainy)\n",
    "    # save model\n",
    "    filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "    model.save(filename)\n",
    "    #print('>Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from numpy import argmax\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stacked model from multiple member input models\n",
    "def define_stacked_model(members):\n",
    "    # update all layers in all models to not be trainable\n",
    "    for i in range(len(members)):\n",
    "        model = members[i]\n",
    "        for layer in model.layers:\n",
    "            # make not trainable\n",
    "            layer.trainable = False\n",
    "            # rename to avoid 'unique layer name' issue\n",
    "            layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "            # define multi-headed input\n",
    "    ensemble_visible = [model.input for model in members]\n",
    "    # concatenate merge output from each model\n",
    "    ensemble_outputs = [model.output for model in members]\n",
    "    merge = concatenate(ensemble_outputs)\n",
    "    hidden = Dense(10, activation='relu')(merge)\n",
    "    output = Dense(6, activation='softmax')(hidden)\n",
    "    model = Model(inputs=ensemble_visible, outputs=output)\n",
    "    # plot graph of ensemble\n",
    "    plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a stacked model\n",
    "def fit_stacked_model(model, inputX, inputy):\n",
    "    # prepare input data\n",
    "    X = [inputX for _ in range(len(model.input))]\n",
    "    # encode output data\n",
    "    inputy_enc = to_categorical(inputy)\n",
    "    # fit model\n",
    "    model.fit(X, inputy_enc, epochs=300, verbose=0)\n",
    "\n",
    "# make a prediction with a stacked model\n",
    "def predict_stacked_model(model, inputX):\n",
    "    # prepare input data\n",
    "    X = [inputX for _ in range(len(model.input))]\n",
    "    # make prediction\n",
    "    return model.predict(X, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_members = 5\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))\n",
    "# define ensemble model\n",
    "stacked_model = define_stacked_model(members)\n",
    "# fit stacked model on test dataset\n",
    "fit_stacked_model(stacked_model, testX, testy)\n",
    "\n",
    "# make predictions and evaluate\n",
    "yhat = predict_stacked_model(stacked_model, testX)\n",
    "yhat = argmax(yhat, axis=1)\n",
    "#print(testy)\n",
    "acc = accuracy_score(testy, yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import precision_score\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "num_folds=10\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "cvscores=[]\n",
    "acc_per_fold=[]\n",
    "loss_per_fold=[]\n",
    "fold_no = 1\n",
    "\n",
    "i=0\n",
    "for train, test in skf.split(X, Y):\n",
    "    \n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "    #X = X.astype('float32')\n",
    "    # Generate the model\n",
    "    \n",
    "    X_train = X[train]\n",
    "    Y_train= Y[train]\n",
    "    \n",
    "    X_test = X[test]\n",
    "    Y_test= Y[test]\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(1, img_rows), strides=(1, 1),input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(1, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.45), bias_regularizer=l2(0.40)))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='Adam',\n",
    "                      metrics=['accuracy',f1,TP,TN,precision_K])\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='accuracy', patience=3, verbose=0)]\n",
    "    if i==0:\n",
    "        model.summary()\n",
    "        \n",
    "        \n",
    "    le = LabelBinarizer()\n",
    "    Y_train = le.fit_transform(Y_train)\n",
    "    Y_test = le.fit_transform(Y_test)\n",
    "    \n",
    "    #metrics = Metrics() \n",
    "    #history = model.fit(X_train, Y_train,\n",
    "     #                   batch_size=100,\n",
    "      #                  epochs=100,\n",
    "       #                 validation_split = 0.10\n",
    "        #             )\n",
    "    \n",
    "    history = model.fit(X_train, Y_train,\n",
    "                      batch_size=100,\n",
    "                      epochs=100,\n",
    "                      validation_split = 0.10,\n",
    "                      callbacks=callbacks, validation_data=(X_test, Y_test))\n",
    "    \n",
    "    ##############accuracy##################################\n",
    "    i = i +1\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Fold \", i ,\"=================================================\")\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    get_classification_report(model,X_test, Y_test)\n",
    "    \n",
    "    ##############Other Metrics##################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "plot_history(history)\n",
    "plotF1(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
